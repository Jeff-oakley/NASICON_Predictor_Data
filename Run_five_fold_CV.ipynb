{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three set of metrics are demonstrated for all data\n",
    "1. 80-20 validation, with validation error demonstrated as peformance metric\n",
    "2. five-fold cross validation, with average CV error demonstrated as performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "\n",
    "prefix = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2D_df = pd.read_csv('train_2D.csv')\n",
    "test_2D_df = pd.read_csv('test_2D.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data according to ehull (the ehull value is calculated as Ehull_DFT - S_ideal*T) and redo the validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       CompName      Ehull  (cbrt(NNaLst)+(AnionChgStdLst)^2)  \\\n",
      "0    MgZr(SO4)3 -60.260567                                0.0   \n",
      "1    MgTi(SO4)3 -27.986572                                0.0   \n",
      "2    MgSn(SO4)3 -30.640966                                0.0   \n",
      "3  Mg4Nb2(SO4)9 -42.783127                                0.0   \n",
      "4    ZrZn(SO4)3 -40.419098                                0.0   \n",
      "\n",
      "   ((EWaldSumLst)^2*(XWithNaLst*RDiffStdLst))  \n",
      "0                                    0.000000  \n",
      "1                                  125.960243  \n",
      "2                                   46.109451  \n",
      "3                                   79.651306  \n",
      "4                                   24.253452  \n"
     ]
    }
   ],
   "source": [
    "print(train_2D_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.] [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "Ehull_train = train_2D_df['Ehull'].to_numpy()\n",
    "Y_total = np.zeros_like(Ehull_train)\n",
    "Y_total[np.where(Ehull_train<=0)] = 1\n",
    "Y_total[np.where(Ehull_train>0)] = 0\n",
    "X_total = train_2D_df[['(cbrt(NNaLst)+(AnionChgStdLst)^2)','((EWaldSumLst)^2*(XWithNaLst*RDiffStdLst))']].to_numpy()\n",
    "\n",
    "Ehull_test = test_2D_df['Ehull'].to_numpy()\n",
    "Y_valid = np.zeros_like(Ehull_test)\n",
    "Y_valid[np.where(Ehull_test<=0)] = 1\n",
    "Y_valid[np.where(Ehull_test>0)] = 0\n",
    "X_valid = test_2D_df[['(cbrt(NNaLst)+(AnionChgStdLst)^2)','((EWaldSumLst)^2*(XWithNaLst*RDiffStdLst))']].to_numpy()\n",
    "print(np.unique(Y_total),np.unique(Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metric on 20% of the validation data (out of the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8236808236808236, recall = 0.8236808236808236, F1 score = 0.839478375313282\n"
     ]
    }
   ],
   "source": [
    "# The SVC validation error from 80-20 splitting\n",
    "\n",
    "clf = SVC(kernel='linear',class_weight='balanced',probability=True)\n",
    "clf.fit(X_total,Y_total)\n",
    "Y_valid_predict = clf.predict(X_valid)\n",
    "test_score = accuracy_score(Y_valid,Y_valid_predict)\n",
    "test_recall = recall_score(Y_valid,Y_valid_predict,average='weighted')\n",
    "test_F1 = f1_score(Y_valid,Y_valid_predict,average='weighted')\n",
    "print(f'Accuracy = {test_score}, recall = {test_recall}, F1 score = {test_F1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance metric on five fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bouyang/miniconda3/envs/work/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_data = np.concatenate((X_total,X_valid))\n",
    "Y_all_data = np.concatenate((Y_total,Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3881,) (3881, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Y_all_data.shape,X_all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6586151368760065, recall = 0.6586151368760065, F1 score = 0.7018645685891012\n",
      "Accuracy = 0.7681159420289855, recall = 0.7681159420289855, F1 score = 0.7968101979983231\n",
      "Accuracy = 0.8341384863123994, recall = 0.8341384863123994, F1 score = 0.850510113330676\n",
      "Accuracy = 0.9162640901771336, recall = 0.9162640901771336, F1 score = 0.9206093171585407\n",
      "Accuracy = 0.917741935483871, recall = 0.917741935483871, F1 score = 0.9089623252575623\n",
      "Average accuracy = 0.8189751181756793, recall = 0.8189751181756793, F1 score = 0.8357513044668406\n"
     ]
    }
   ],
   "source": [
    "# The real train set = train set from skf + the validation data set\n",
    "accuracy_lst, recall_lst, F1_lst = [], [], []\n",
    "\n",
    "for train_index, test_index in skf.split(X_total,Y_total):\n",
    "    X_train = np.concatenate((X_all_data[train_index],X_all_data))\n",
    "    X_test = X_total[test_index]\n",
    "    Y_train = np.concatenate((Y_all_data[train_index],Y_all_data))\n",
    "    Y_test = Y_total[test_index]\n",
    "    \n",
    "    clf = SVC(kernel='linear',class_weight='balanced',probability=True)\n",
    "\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_cv_predict = clf.predict(X_test)\n",
    "    \n",
    "    test_score = accuracy_score(Y_test,Y_cv_predict)\n",
    "    test_recall = recall_score(Y_test,Y_cv_predict,average='weighted')\n",
    "    test_F1 = f1_score(Y_test,Y_cv_predict,average='weighted')\n",
    "    \n",
    "    accuracy_lst.append(test_score)\n",
    "    recall_lst.append(test_recall)\n",
    "    F1_lst.append(test_F1)\n",
    "    \n",
    "    print(f'Accuracy = {test_score}, recall = {test_recall}, F1 score = {test_F1}')\n",
    "    \n",
    "print(f'Average accuracy = {np.average(accuracy_lst)}, recall = {np.average(recall_lst)}, F1 score = {np.average(F1_lst)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyCondaEnv",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
